)
2  name:  conv1 layer:  Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([16, 3, 3, 3])
6  name:  layer1.0.conv1 layer:  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([16, 16, 3, 3])
8  name:  layer1.0.conv2 layer:  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([16, 16, 3, 3])
12  name:  layer1.1.conv1 layer:  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([16, 16, 3, 3])
14  name:  layer1.1.conv2 layer:  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([16, 16, 3, 3])
18  name:  layer1.2.conv1 layer:  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([16, 16, 3, 3])
20  name:  layer1.2.conv2 layer:  Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([16, 16, 3, 3])
25  name:  layer2.0.conv1 layer:  Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
weights shape:  torch.Size([32, 16, 3, 3])
27  name:  layer2.0.conv2 layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([32, 32, 3, 3])
31  name:  layer2.1.conv1 layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([32, 32, 3, 3])
33  name:  layer2.1.conv2 layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([32, 32, 3, 3])
37  name:  layer2.2.conv1 layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([32, 32, 3, 3])
39  name:  layer2.2.conv2 layer:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([32, 32, 3, 3])
44  name:  layer3.0.conv1 layer:  Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
weights shape:  torch.Size([64, 32, 3, 3])
46  name:  layer3.0.conv2 layer:  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([64, 64, 3, 3])
50  name:  layer3.1.conv1 layer:  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([64, 64, 3, 3])
52  name:  layer3.1.conv2 layer:  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([64, 64, 3, 3])
56  name:  layer3.2.conv1 layer:  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([64, 64, 3, 3])
58  name:  layer3.2.conv2 layer:  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
weights shape:  torch.Size([64, 64, 3, 3])
62 name:  linear  layer:  Linear(in_features=64, out_features=2, bias=True)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 16, 224, 224]             432
       BatchNorm2d-2         [-1, 16, 224, 224]              32
            Conv2d-3         [-1, 16, 224, 224]           2,304
       BatchNorm2d-4         [-1, 16, 224, 224]              32
            Conv2d-5         [-1, 16, 224, 224]           2,304
       BatchNorm2d-6         [-1, 16, 224, 224]              32
        BasicBlock-7         [-1, 16, 224, 224]               0
            Conv2d-8         [-1, 16, 224, 224]           2,304
       BatchNorm2d-9         [-1, 16, 224, 224]              32
           Conv2d-10         [-1, 16, 224, 224]           2,304
      BatchNorm2d-11         [-1, 16, 224, 224]              32
       BasicBlock-12         [-1, 16, 224, 224]               0
           Conv2d-13         [-1, 16, 224, 224]           2,304
      BatchNorm2d-14         [-1, 16, 224, 224]              32
           Conv2d-15         [-1, 16, 224, 224]           2,304
      BatchNorm2d-16         [-1, 16, 224, 224]              32
       BasicBlock-17         [-1, 16, 224, 224]               0
           Conv2d-18         [-1, 32, 112, 112]           4,608
      BatchNorm2d-19         [-1, 32, 112, 112]              64
           Conv2d-20         [-1, 32, 112, 112]           9,216
      BatchNorm2d-21         [-1, 32, 112, 112]              64
      LambdaLayer-22         [-1, 32, 112, 112]               0
       BasicBlock-23         [-1, 32, 112, 112]               0
           Conv2d-24         [-1, 32, 112, 112]           9,216
      BatchNorm2d-25         [-1, 32, 112, 112]              64
           Conv2d-26         [-1, 32, 112, 112]           9,216
      BatchNorm2d-27         [-1, 32, 112, 112]              64
       BasicBlock-28         [-1, 32, 112, 112]               0
           Conv2d-29         [-1, 32, 112, 112]           9,216
      BatchNorm2d-30         [-1, 32, 112, 112]              64
           Conv2d-31         [-1, 32, 112, 112]           9,216
      BatchNorm2d-32         [-1, 32, 112, 112]              64
       BasicBlock-33         [-1, 32, 112, 112]               0
           Conv2d-34           [-1, 64, 56, 56]          18,432
      BatchNorm2d-35           [-1, 64, 56, 56]             128
           Conv2d-36           [-1, 64, 56, 56]          36,864
      BatchNorm2d-37           [-1, 64, 56, 56]             128
      LambdaLayer-38           [-1, 64, 56, 56]               0
       BasicBlock-39           [-1, 64, 56, 56]               0
           Conv2d-40           [-1, 64, 56, 56]          36,864
      BatchNorm2d-41           [-1, 64, 56, 56]             128
           Conv2d-42           [-1, 64, 56, 56]          36,864
      BatchNorm2d-43           [-1, 64, 56, 56]             128
       BasicBlock-44           [-1, 64, 56, 56]               0
           Conv2d-45           [-1, 64, 56, 56]          36,864
      BatchNorm2d-46           [-1, 64, 56, 56]             128
           Conv2d-47           [-1, 64, 56, 56]          36,864
      BatchNorm2d-48           [-1, 64, 56, 56]             128
       BasicBlock-49           [-1, 64, 56, 56]               0
      BatchNorm1d-50                   [-1, 64]             128
           Linear-51                    [-1, 2]             130
================================================================
Total params: 269,330
Trainable params: 269,330
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 177.63
Params size (MB): 1.03
Estimated Total Size (MB): 179.23
----------------------------------------------------------------
